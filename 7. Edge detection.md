Edge detection
===
# 에지 검출과 응용

## 미분
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/06f5109d-b89e-4d5c-a064-d7ba69330a4c)<br>
> 픽셀 값이 급격하게 변하는 지점 찾기 (f′(x) 값이 0보다 훨씬 크거나 또는 훨씬 작은 위치를 찾아야) <br>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/6aaf64d9-0b6b-4969-adeb-0d97b5b21ae6)<br>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/9770c095-ee93-4c49-b79d-dc1f780d2714)<br>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/b025ccd5-4835-4f2d-8b81-34825a2acfea)<br>
>
> 위의 세 방식 (전진, 후진, 중앙 차분) 중에서 **중앙 차분**이 근사오류가 가장 적다. <br>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/efba92a8-50b4-4cf4-b279-ce18230f5c17)<br>
>
> 위는 중앙 차분에 의한 미분 근사 Mask
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/22d1b71e-25c8-4d6f-8e28-8f9b20ae5bbd)<br>

## 그래디언트 
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/d44a347a-8b61-48ad-ab7e-53005ba9ffbe)<br>
>
>  f(x, y)가 있을 때 이 함수의 x축 방향 미분과 y축 방향 미분을 한꺼번에 **벡터로 표현**한 것 <br>
> 그래디언트 벡터의 **방향**은 픽셀 값이 가장 **급격하게 증가하는 방향** <br>
> 그래디언트 벡터의 **크기**는 픽셀 값의 차이 정도, **변화량** <br>
>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/350aae51-612e-454b-a128-d8951f22e408)<br>
>
> 위의 그림에서 경계상의 세 점 a, b, c를 선택하고, 각 점에서의 그래디언트 벡터를 빨간색 화살표로 표현 <br>
> 노란색으로 표시된 화살표는 **그래디언트 벡터와 수직인 방향**을 표시, **'에지의 방향'** <br>
> 2차원 영상에서 에지를 찾는 기본적인 방법은 **그래디언트 크기가 특정 값보다 큰 위치를 찾는 것** <br>
> 임계값을 높게 설정하면 밝기 차이가 급격하게 변하는 에지 픽셀만 검출 <br>
> 임계값을 낮게 설정하면 약한 에지 성분도 검출 <br>

### 2D 벡터의 크기 계산 함수
<pre>
	<code>
		cv2.magnitude(x, y, magnitude=None) -> magnitude
	</code>
</pre>

### 2D 벡터의 방향 계산 함수
<pre>
	<code>
		cv2.phase(x, y, angle=None, angleInDegrees=None) -> angle
	</code>
</pre>

## Mask 기반 Edge 검출 
### Sobel filter 
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/576867b4-eb81-49e2-93d7-5d3b3c88a754)<br>
>
> 축 방향 미분 마스크는 현재 행에 대한 중앙 차분 연산을 2회 <br>
> 이전 행과 다음 행에 대해서도 중앙 차분 연산을 1회 <br>
> (현재 행과 이웃 행에서의 픽셀 값 변화가 유사하다는 점을 이용하여 잡음의 영향을 줄이기 위함) <br>
> (현재 행에서 두 번의 중앙 차분 연산을 수행하는 것은 현재 행의 중앙 차분 근사에 더 큰 가중치를 주기 위함) <br>
> (b)는 y축 방향 미분 계산 <br>

### Sobel filter 를 이용한 Edge 검출 예제
<pre>
	<code>
		src = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)

		dx = cv2.Sobel(src, cv2.CV_32F, 1, 0)
		dy = cv2.Sobel(src, cv2.CV_32F, 0, 1)
		
		mag = cv2.magnitude(dx, dy)
		mag = np.clip(mag, 0, 255).astype(np.uint8)
		
		dst = np.zeros(src.shape[:2], np.uint8)
		dst[mag > 120] = 255 # threshold(120) 역할
	</code>
</pre>

### 샤르 필터 (Scharr filter)
![image](https://github.com/god102104/openCV_Practice/assets/43011129/a4dd2782-2eb0-4fa9-a3e4-38d9c25a46d2)

> **Sobel 보다 더 정확함**


### Edge 검출 결과 (Sobel)
![image](https://github.com/god102104/openCV_Practice/assets/43011129/fa8c9d99-de71-4bfa-b8c6-046b391aca64)

### 캐니 에지 검출기 (canny edge detector)

> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/dd52a5fe-b866-4fd9-b9e2-28206fbab508)<br>
>
> 위는 캐니 에지 검출기 수행 과정
>
> 1. 가우시안 필터링 <br>
> 2. 그래디언트 계산 : 3x3 Sobel mask 주로 사용. Canny 에서는 정확한 Edge 검출을 위해 **Gradient 방향도 고려**. <br>
> 3. 비최대 억제 : 단순히 그래디언트 크기가 특정 임계값보다 큰 픽셀을 선택할 경우, <br>
>    에지 근방의 여러 픽셀이 한꺼번에 에지로 선택될 수도 있음. <br>
>    **에지가 두껍게 표현되는 현상을 방지**하기 위해 캐니 에지 검출기에서는 <br>
>    비최대 억제(non-maximum suppression) 과정을 사용 <br>
>    그래디언트 크기가 국**지적 최대(local maximum)인 픽셀만을 에지 픽셀로** 설정 <br>
>    **가장 변화율이 큰 위치**의 픽셀만 에지로 <br>
> ### Canny - 이중 임계값을 이용한 히스테리시스 에지 트래킹
> 소벨 에지 검출 방법에서는 그래디언트 크기가 특정 임계값보다 크면 에지 픽셀로, <br>
> 작으면 에지가 아닌 픽셀로 판단. <br>
> 이 경우 **조명**이 조금 바뀌거나 또는 **임계값**을 조금만 조절해도 **에지 픽셀 판단 결과가 크게 달라질 수**도. <br>
> 캐니 에지 검출기에서는 **두 개의 임계값**
> Canny() 함수

<pre>
	<code>
		void Canny(InputArray image, OutputArray edges,
		           double threshold1, double threshold2,
		           int apertureSize = 3, bool L2gradient = false);
		void Canny(InputArray dx, InputArray dy, OutputArray edges,
		           double threshold1, double threshold2,
		           bool L2gradient = false);
	</code>
</pre>

### Canny Edge 검출 예제
<pre>
	<code>
		 void canny_edge()
		    {
		        Mat src = imread("lenna.bmp", IMREAD_GRAYSCALE);
		     
		        if (src.empty()) {
		            cerr << "Image load failed!" << endl;
		            return;
		        }
		     
		        Mat dst1, dst2;
		        Canny(src, dst1, 50, 100);
		        Canny(src, dst2, 50, 150);
		     
		        imshow("src", src);
		        imshow("dst1", dst1);
		        imshow("dst2", dst2);
		     
		        waitKey();
		        destroyAllWindows();
		    }
	</code>
</pre>
>![image](https://github.com/god102104/openCV_Practice/assets/43011129/b46216b2-b9f1-4cc3-928a-98f035b470a3)<br>
>
> 각각 임계값 100, 150 인 경우. 


# 직선 검출과 원 검출

## 허프 변환 직선 검출
> 영상에서 직선 성분을 찾기 위해서는 우선 에지를 찾아내고, 에지 픽셀들이 일직선상에 배열되어 있는지를 확인 <br>
> 영상에서 **직선을 찾기 위한** 용도로 **허프 변환(hough transform)** 기법이 널리 사용 <br>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/6e788ff7-85d1-41b4-970e-1cc95ef46e11)<br>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/ecfcc734-ccd4-4b47-a969-7f07990f47ef)<br>
>
> xy 공간에서 직선의 방정식을 ab 공간으로 변경
>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/41184a67-605f-433f-aa7e-c16e4959f9e9)<br>
>
> 허프 변환을 이용하여 직선의 방정식을 찾으려면 <br>
> xy 공간에서 **에지로 판별된 모든 점을 이용**하여 ab **파라미터 공간에 직선을 표현**하고, <br>
> **직선이 많이 교차되는 좌표를 모두 찾아야** <br>
> 직선이 많이 교차하는 점을 찾기 위해서 보통 **축적 배열(accumulation array)을 사용** <br>
> 축적 배열은 0으로 초기화된 2차원 배열에서 직선이 지나가는 위치의 배열 원소 값을 1씩 증가시켜 생성 <br>
>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/1c5164a2-bb6a-4a77-8565-86c4522b8745)<br>
>
> 그러나 y=ax+b 형태의 직선의 방정식을 사용할 경우 **모든 형태의 직선을 표현하기 어렵다** 는 단점 <br>
>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/01757e63-f555-4995-b8e7-6b171a67d48d)<br>
>
> **극좌표계 형식**으로 표현된 직선의 방정식을 쓰면 된다. <br>
>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/7326c0db-97a2-4cf1-99a3-f9c1f1c2f4ca)<br>
>
> **HoughLines()** 함수로 허프 변환 직선 검출 
> <pre>
>	<code>
>		void HoughLines(InputArray image, OutputArray lines,
>                double rho, double theta, int threshold,
>                double srn = 0, double stn = 0,
>                double min_theta = 0, double max_theta = CV_PI);
>	</code>
> </pre>
>• image : 8비트 단일 채널 입력 영상. 주로 에지 영상을 지정. <br>
>	보통 **Canny() 함수 등을 이용하여 구한 에지 영상을 지정** <br>
>• lines : 직선 정보(rho, theta)를 저장할 출력 벡터 <br>
>• rho : 축적 배열에서 ρ 값의 해상도(픽셀 단위) <br>
>• theta : 축적 배열에서 θ 값의 해상도(라디안 단위) <br>
>• threshold : 축적 배열에서 직선으로 판단할 임계값 <br>
>• srn : 멀티스케일 허프 변환에서 rho 해상도를 나누는 값. <br>
>	srn에 양의 실수를 지정하면 rho 해상도와 rho/srn 해상도를 각각 이용하여 멀티스케일 허프 변환을 수행. <br>
>	srn과 stn이 모두 0이면 일반 허프 변환을 수행. <br>
>• stn : 멀티스케일 허프 변환에서 theta 해상도를 나누는 값 <br>
>• min_theta : 검출할 직선의 최소 theta 값 <br>
>• max_theta : 검출할 직선의 최대 theta 값

### 허프 변환 직선 검출 예시 코드
<pre>
	<code>
		#include "opencv2/opencv.hpp"
		#include <iostream>
		
		using namespace cv;
		using namespace std;
		
		void hough_lines();
		void hough_line_segments();
		void hough_circles();
		
		int main(void)
		{
			hough_lines();
			hough_line_segments();
			hough_circles();
		
			return 0;
		}
		
		void hough_lines()
		{
			Mat src = imread("building.jpg", IMREAD_GRAYSCALE);
		
			if (src.empty()) {
				cerr << "Image load failed!" << endl;
				return;
			}
		
			Mat edge;
			Canny(src, edge, 50, 150);
		
			vector<Vec2f> lines;
			HoughLines(edge, lines, 1, CV_PI / 180, 250);
		
			Mat dst;
			cvtColor(edge, dst, COLOR_GRAY2BGR);
		
			for (size_t i = 0; i < lines.size(); i++) {
				float rho = lines[i][0], theta = lines[i][1];
				float cos_t = cos(theta), sin_t = sin(theta);
				float x0 = rho * cos_t, y0 = rho * sin_t;
				float alpha = 1000;
		
				Point pt1(cvRound(x0 - alpha * sin_t), cvRound(y0 + alpha * cos_t));
				Point pt2(cvRound(x0 + alpha * sin_t), cvRound(y0 - alpha * cos_t));
				line(dst, pt1, pt2, Scalar(0, 0, 255), 2, LINE_AA);
			}
		
			imshow("src", src);
			imshow("dst", dst);
		
			waitKey();
			destroyAllWindows();
		}
		
		void hough_line_segments()
		{
			Mat src = imread("building.jpg", IMREAD_GRAYSCALE);
		
			if (src.empty()) {
				cerr << "Image load failed!" << endl;
				return;
			}
		
			Mat edge;
			Canny(src, edge, 50, 150);
		
			vector<Vec4i> lines;
			HoughLinesP(edge, lines, 1, CV_PI / 180, 160, 50, 5);
		
			Mat dst;
			cvtColor(edge, dst, COLOR_GRAY2BGR);
		
			for (Vec4i l : lines) {
				line(dst, Point(l[0], l[1]), Point(l[2], l[3]), Scalar(0, 0, 255), 2, LINE_AA);
			}
		
			imshow("src", src);
			imshow("dst", dst);
		
			waitKey();
			destroyAllWindows();
		}
		
		void hough_circles()
		{
			Mat src = imread("coins.png", IMREAD_GRAYSCALE);
		
			if (src.empty()) {
				cerr << "Image load failed!" << endl;
				return;
			}
		
			Mat blurred;
			blur(src, blurred, Size(3, 3));
		
			vector<Vec3f> circles;
			HoughCircles(blurred, circles, HOUGH_GRADIENT, 1, 50, 150, 30);
		
			Mat dst;
			cvtColor(src, dst, COLOR_GRAY2BGR);
		
			for (Vec3f c : circles) {
				Point center(cvRound(c[0]), cvRound(c[1]));
				int radius = cvRound(c[2]);
				circle(dst, center, radius, Scalar(0, 0, 255), 2, LINE_AA);
			}
		
			imshow("src", src);
			imshow("dst", dst);
		
			waitKey();
			destroyAllWindows();
		}
	</code>
</pre>
![image](https://github.com/god102104/openCV_Practice/assets/43011129/722984bd-f731-43c4-b43f-0fe45553eea3)<br>

## 허프 변환 원 검출
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/dd77d147-bb00-4801-99b1-fee4156694b8)<br>
>
> 원의 방정식은 세 개의 파라미터 <br>
> 허프 변환을 그대로 적용하려면 3차원 파라미터 공간에서 축적 배열을 정의하고 <br>
> 가장 누적이 많은 위치를 찾아야... → 너무 많은 메모리와 연산 시간 필요 <br>
> 그래서, OpenCV에서는 일반 허프 변환 대신 **허프 그래디언트 방법(Hough gradient method)** 사용 **원 검출** <br>

### 허프 그래디언트 방법의 순서
> 1. 영상에 존재하는 모든 원의 중심 좌표 찾기 (축적 배열 이용) <br>
> 2. 검출된 원의 중심으로부터 원에 적합한 반지름을 구함 <br>
> 원의 중심을 찾기 위해 허프 그래디언트 방법 : 입력 영상의 모든 에지 픽셀에서 그래디언트를 구하고, <br>
> 그래디언트 방향을 따르는 직선상의 축적 배열 값을 1씩 증가 <br>
>
> ![image](https://github.com/god102104/openCV_Practice/assets/43011129/2585e4bc-d42b-4ea8-b10c-fc1776ffccc7)<br>
>
> 단점 1 : 여러 개의 동심원을 검출하지 못함 <br>
> 단점 2 : 가장 작은 원 하나만 검출 <br>
>
> <pre>
>	<code>
>		cv2.HoughCircles(image, 
>		method, dp, minDist, circles=None, 
>	 	param1=None, param2=None, minRadius=None, 
>	  	maxRadius=None) -> circles
>	</code>
> </pre>

### 허프 변환 원 검출 예제
<pre>
	<code>
		src = cv2.imread('dial.jpg')
		gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
		blr = cv2.GaussianBlur(gray, (0, 0), 1.0)
		
		def on_trackbar(pos):
		    rmin = cv2.getTrackbarPos('minRadius', 'img')
		    rmax = cv2.getTrackbarPos('maxRadius', 'img')
		    th = cv2.getTrackbarPos('threshold', 'img')
		    
		    circles = cv2.HoughCircles(blr, cv2.HOUGH_GRADIENT, 1, 50, 
			param1=120, param2=th, minRadius=rmin, maxRadius=rmax)
		    dst = src.copy()
		    
		    if circles is not None:
		        for i in  range(circles.shape[1]):
		            cx, cy, radius = circles[0][i]
		            cv2.circle(dst, (int(cx), int(cy)), int(radius), (0, 0, 255), 2, cv2.LINE_AA)
	</code>
</pre>


![screensh](https://velog.velcdn.com/images%2Fredorangeyellowy%2Fpost%2F2e3f6585-a4a9-44e8-8787-62506d5fc07f%2Fcircle.gif)

